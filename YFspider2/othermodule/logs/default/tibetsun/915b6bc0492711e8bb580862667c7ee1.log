2018-04-26 16:00:13 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: YFspider2)
2018-04-26 16:00:13 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'YFspider2.spiders', 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_MODULES': ['YFspider2.spiders'], 'REACTOR_THREADPOOL_MAXSIZE': '32', 'BOT_NAME': 'YFspider2', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'logs\\default\\tibetsun\\915b6bc0492711e8bb580862667c7ee1.log'}
2018-04-26 16:00:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-04-26 16:00:13 [tibetsun] INFO: Reading start URLs from redis key 'tibetsun:start_urls' (batch size: 16, encoding: utf-8
2018-04-26 16:00:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-04-26 16:00:13 [py.warnings] WARNING: D:\python_27\lib\site-packages\scrapy\utils\deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.spidermiddleware.referer.RefererMiddleware` class is deprecated, use `scrapy.spidermiddlewares.referer.RefererMiddleware` instead
  ScrapyDeprecationWarning)

2018-04-26 16:00:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-04-26 16:00:13 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy_redis.pipelines.RedisPipeline',
 'YFspider2.pipelines.YfspidersetdefaultValue',
 'YFspider2.pipelines.save_data_to_RemoteFile_XMX',
 'YFspider2.pipelines.save_data_to_file']
2018-04-26 16:00:13 [scrapy.core.engine] INFO: Spider opened
2018-04-26 16:00:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-04-26 16:00:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6047
2018-04-26 16:00:15 [tibetsun] DEBUG: Read 1 requests from 'tibetsun:start_urls'
2018-04-26 16:00:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/> (referer: None)
2018-04-26 16:00:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/news/2018/04/26/meeting-dalai-lama-would-spark-crisis-with-china-macron> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:19 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.tibetsun.com/news/2018/04/26/meeting-dalai-lama-would-spark-crisis-with-china-macron> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-04-26 16:00:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tibetsun.com/news/2018/04/26/meeting-dalai-lama-would-spark-crisis-with-china-macron>
{'ancestor_id': None,
 'content': u'French President Emmanuel Macron on Wednesday rejected the prospect of meeting with the Dalai Lama, saying doing so without consulting Beijing first would trigger a \u201ccrisis\u201d with China\u2019s government. Macron, speaking at a town hall with George Washington University students in the US capital at the tail end of his state visit, said he met in Paris with the \u201cvery inspiring\u201d exiled Tibetan spiritual leader when Macron was a candidate. \u201cNow I\u2019m president of the French republic. If I meet him it will create indeed a crisis with China,\u201d Macron said. And doing so \u201cwithout any precondition,\u201d just to send a signal to China, would be \u201cuseless and counterproductive,\u201d he said. \u201cIs it good for my people if I have a sort of countermeasures coming from China\u201d as a result of the meeting? \u201cFor sure no.\u201d But Macron, fresh from a rare address to lawmakers in the US Congress, also opened the door for deeper engagement on the issue. \u201cIf France could be useful in order to fix the situation between the Dalai Lama and his people, and China, I will do my best,\u201d he said, adding that he perceives \u201csome early signals\u201d that Chinese President Xi Jinping may be open to addressing the issue. \u201cI hope so for China, I hope so for the Dalai Lama, I hope so for Buddhist people,\u201d he added. Beijing accuses the Nobel Peace Prize laureate of seeking Tibetan independence through \u201cspiritual terrorism.\u201d The Dalai Lama says he seeks only greater autonomy.',
 'dislike_count': None,
 'id': 'meeting-dalai-lama-would-spark-crisis-with-china-macron',
 'img_urls': [u'https://media.tibetsun.com/images/news/2018/04/meeting-dalai-lama-would-spark-crisis-with-china-macron-pg.jpg'],
 'is_pic': None,
 'like_count': None,
 'like_nodes': None,
 'parent_id': None,
 'publish_time': '2018-04-26 00:00:00',
 'publish_user': None,
 'publish_user_id': None,
 'publish_user_jsonid': None,
 'publish_user_photo': None,
 'read_count': None,
 'reply_count': 0,
 'reply_nodes': None,
 'reproduce_count': None,
 'spider_time': 1524729619279L,
 'title': u'Meeting Dalai Lama would spark \u2018crisis\u2019 with China: Macron',
 'txpath': None,
 'url': 'https://www.tibetsun.com/news/2018/04/26/meeting-dalai-lama-would-spark-crisis-with-china-macron',
 'video_urls': None}
2018-04-26 16:00:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/features/2018/03/17/the-spirit-of-little-tibet> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/have_your_say/2018/03/02/how-should-tibetans-prepare-for-a-long-term-xi-jinping> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/letters-to-the-editor/2018/04/06/investigation-into-mr-dhundup-nyarong> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tibetsun.com/features/2018/03/17/the-spirit-of-little-tibet>
{'ancestor_id': None,
 'content': u'There are many reasons to go to Dharamshala. It is one of Himachal Pradesh\u2019s most important towns. It now has its own cricket stadium. It has a beautiful location at the foot of the Himalayas. But, in truth, there is only one reason why it has come to so much global attention. In 1960, the Dalai Lama moved to Dharamshala, then a sleepy ghost town, and set up the Tibetan government-in-exile. He chose the suburb of McLeod Ganj, a few miles away from the main city, and the Tibetans built imposing structures, including the house where the Dalai Lama himself lives. Over time, more and more Tibetans fled from Chinese rule and settled in Dharamshala, to the extent that something like 30 per cent of the population is Tibetan. But because the Tibetans are concentrated in McLeod Ganj, it often feels like there are many more of them, and McLeod Ganj is known as Little Tibet. The one time I had interviewed the Dalai Lama was over a decade ago for the Hindustan Times , and we met in a hotel room in Delhi. He was in great form, spoke with his usual conviction, and the interview caused a splash when it was published. But the idea of going to Dharamshala had never occurred to me. Then, a year ago, the producer of my TV show, Chetan Dhalla, became obsessed with the idea of a Dalai Lama interview. He began communicating with Tseten Samdup Chhoekyapa, who handles these things for the Dalai Lama. Chetan was told off roundly for even broaching the idea and informed that, at that very moment, the Dalai Lama\u2019s office was handling over 200 requests from all over the world. Did he think he could demand an interview just like that? But Chetan kept at it and in late February, he got a call. The Dalai Lama was ready to give the interview. But I would have to come to Dharamshala to do it. And there was only a brief window of one or two days when he could do it. I\u2019ll be honest: I was reluctant to go to Dharamshala. Not because I did not want to interview the Dalai Lama (of course, I did!), but because the best way of getting there is by a small propeller plane and I have terrible claustrophobia. We explored the driving option but that took around 10 to 12 hours. And though our crew finally drove to Dharamshala, I tranquillised myself and took the plane, my nerves numbed by medication. I stayed at the Fortune Park Moksha, a modern hotel that is probably the best in the area with spectacular views of the Himalayas, and the evening before the interview, I headed to the complex where the Dalai Lama and his aides run their government-in-exile. Tseten took me to dinner at a restaurant next door which he said served authentic Tibetan food. The food, when it came, was great. I was particularly intrigued by the momos, Tibet\u2019s greatest contribution to world cuisine. The momo, as we know it in Delhi or Mumbai, is no more than a Chinese-style dim sum. The reason most restaurants describe it as a momo is because this allows them to pack it with all kinds of masaledaar fillings of the kind you could never put into a Chinese dim sum, even in the most renowned Sino-Ludhianvi restaurants. But Tibetan momos are not meant to be delicate Chinese-style dumplings. They are a simple dish, made all over the countryside, usually with minced yak meat and normal atta. Our momos in Dharamshala had no yak meat, but they did not have the masalas we associate with momos in the rest of the India either. More significantly, they were made with atta, not the very fine maida used for momos outside of Dharamshala. So the dough was thick and the dish had a more rustic, less Chinese feel to it. I asked Tseten if they ate this kind of food every day. His answer surprised me. He ate most meals in the complex\u2019s cafeteria, which was entirely vegetarian. Further, it did not specialise in Tibetan cuisine but served Indian food. Why was that, I asked. Tibetans are not vegetarians, nor does their version of Buddhism require them to abjure meat. He replied that after so many years in India, Tibetans had become more Indian than some of us realised. The Dalai Lama had also turned vegetarian. But some years ago, he fell very ill and was advised by doctors to eat some meat for health reasons. Early the next morning, I set out again for the Dalai Lama\u2019s complex. My crew, who had driven from Delhi (it took them 12 hours), were ready in a meeting room where the Dalai Lama gives audiences to visitors. Except that nobody was sure when the Dalai Lama would actually make it to the interview. I looked out into the courtyard where a large crowd had gathered. Many (if not most) of those waiting were not Tibetans but were Indians. When the Dalai Lama appeared to meet them, there was a discernible emotional reaction. First, one woman wept on seeing him. Then, the men rushed to touch his feet in the Indian (but not necessarily Tibetan) manner. Next, even more people seemed overcome with emotion. I watched the Dalai Lama closely. Unlike our own saints and gurus who treat such displays of reverence by solemnly offering blessings, the Dalai Lama made a conscious effort to lighten the mood by laughing and joking with those who were being so serious and worshipful. He was patient with everyone who had something to say. So patient, in fact, that I began to wonder when the interview would begin. We were already half an hour behind schedule and there was only one flight out of Dharamshala that day. If the interview did not begin soon, I was going to miss that flight. When he finished with that group of visitors, I breathed a sigh of relief. But no, it turned out that there was another group waiting to meet him. I guess the Dalai Lama sensed how tense we were getting because as he passed, he stopped by our window, looked directly at my wife, blew his cheeks out, made a funny face and laughed. It took us so completely by surprise that it broke the tension. When he finally did arrive and we settled down to shoot (over an hour behind schedule), I reminded him of our first interview. Legend has it that each Dalai Lama is reincarnated after he dies. So monks scour Tibet looking for a child who seems to be the reincarnation. But, in Delhi, the Dalai Lama had told me that he was not the reincarnation of his predecessor. Yes, he said, he had vivid recollections of the life of a previous Dalai Lama, but not of his immediate predecessor. More interestingly, he said, the dreams he now had were not of a Tibetan monk at all but of \u201cthe great Hindu master Krishna.\u201d I told him that this kind of figured, because though Tibetans don\u2019t accept this, Hinduism regards the Buddha as an avatar of Vishnu. And Lord Krishna is also a Vishnu-avatar. So from a Hindu (though not Tibetan) perspective, this had a certain logic to it. Then, we were ready to roll. I won\u2019t say much about the interview because it was telecast a week ago (the deadlines in magazine journalism are very different from those of TV). But once again, he took us by surprise. We were interviewing him on the 60th anniversary of his arrival in India. Grand celebrations had been planned but everything was scaled back in the days before our interview took place. Papers reported that the government of India did not wish to offend the Chinese, who hate the Dalai Lama. The night before, at dinner, Tsetan had been eager to emphasise that this interview would be about philosophy and not politics. But within a few minutes, the Dalai Lama was talking politics. At some level, he was also a Marxist, he laughed, because he believed in the advancement of the working class. What he objected to was the tyranny of Communist regimes. And on and on he went about China, its totalitarian regime, its oppression of the Tibetan people, etc. etc. We ended the interview after 46 minutes. I thanked him, but he insisted on staying to meet every member of the crew. He went up to my wife (who comes on most shoots with us) and pinched her cheek. He tickled our principal video journalist Gurmeet Singh Bedi\u2019s beard and giggled. \u201cHello sardarji,\u201d he said. By the time we were finally ready to leave, I was sure I had missed my flight. But what do you know? It had been delayed by two hours and there was no need to rush. The Dalai Lama had said before our interview: \u201cYou must not worry about things. It will be all right.\u201d I don\u2019t think he had the flight in mind. But still \u2026',
 'dislike_count': None,
 'id': 'the-spirit-of-little-tibet',
 'img_urls': [u'https://media.tibetsun.com/images/features/2018/03/the-spirit-of-little-tibet-pg.jpg'],
 'is_pic': None,
 'like_count': None,
 'like_nodes': None,
 'parent_id': None,
 'publish_time': '2018-03-17 00:00:00',
 'publish_user': None,
 'publish_user_id': None,
 'publish_user_jsonid': None,
 'publish_user_photo': None,
 'read_count': None,
 'reply_count': 0,
 'reply_nodes': None,
 'reproduce_count': None,
 'spider_time': 1524729621039L,
 'title': u'The spirit of Little Tibet',
 'txpath': None,
 'url': 'https://www.tibetsun.com/features/2018/03/17/the-spirit-of-little-tibet',
 'video_urls': None}
2018-04-26 16:00:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tibetsun.com/have_your_say/2018/03/02/how-should-tibetans-prepare-for-a-long-term-xi-jinping>
{'ancestor_id': None,
 'content': u'After Vladimir Putin of Russia and Recep Tayyip Erdogan of Turkey, Xi Jinping of China will become the third world leader to hold the reins of power for a long duration by manipulating political and constitutional processes. On 15 November 2012, Xi succeeded Hu Jintao as the General Secretary of the CPC Central Committee and as Chairman of the Communist Party\u2019s Central Military Commission. As the paramount leader of China, Xi\u2019s approach has been to establish China as a global player and tighten control of society to consolidate power to bolster the Party\u2019s control of China. Xi has overseen increased stifling of people\u2019s rights and freedoms, marking his own ascent to becoming the most powerful leader of China since Mao Zedong. Xi having consolidated his own political power and reluctant to let go of it, under his influence the Party is widely expected to rewrite its constitution to pave the way for him to become life-long leader of China. At the National People\u2019s Congress session in Beijing from 5 March, the Congress will consider amending the country\u2019s constitution. Among the 21 amendments proposed by the Communist Party of China, the most controversial is paragraph 3 of article 79, which would eradicate the current limit of PRC presidents and vice-presidents to two five-year terms. If that goes into effect, Xi Jinping, now 64, will be free to stay on as China\u2019s head of state indefinitely. Xi is no doubt reversing China\u2019s march towards openness and rule of law. This is the new China that the world will be dealing with.',
 'dislike_count': None,
 'id': 'how-should-tibetans-prepare-for-a-long-term-xi-jinping',
 'img_urls': [u'https://media.tibetsun.com/images/have_your_say/2018/03/how-should-tibetans-prepare-for-a-long-term-xi-jinping-pg.jpg'],
 'is_pic': None,
 'like_count': None,
 'like_nodes': None,
 'parent_id': None,
 'publish_time': '2018-03-02 00:00:00',
 'publish_user': None,
 'publish_user_id': None,
 'publish_user_jsonid': None,
 'publish_user_photo': None,
 'read_count': None,
 'reply_count': 0,
 'reply_nodes': None,
 'reproduce_count': None,
 'spider_time': 1524729621119L,
 'title': u'How should Tibetans prepare for a long-term Xi Jinping?',
 'txpath': None,
 'url': 'https://www.tibetsun.com/have_your_say/2018/03/02/how-should-tibetans-prepare-for-a-long-term-xi-jinping',
 'video_urls': None}
2018-04-26 16:00:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/letters-to-the-editor/2018/04/06/investigation-into-mr-dhundup-nyarong> (referer: https://www.tibetsun.com/)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python_27\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "F:\project_coding\YFZX2\YFspider2\YFspider2\spiders\tibetsun.py", line 127, in parse_content
    loader1.add_value('reply_nodes',response.selector.xpath('//ol[@class="commentlist"]/li[contains(@class,"comment")]'),deal_reply_nodes)
  File "D:\python_27\lib\site-packages\scrapy\loader\__init__.py", line 70, in add_value
    value = self.get_value(value, *processors, **kw)
  File "D:\python_27\lib\site-packages\scrapy\loader\__init__.py", line 109, in get_value
    value = proc(value)
  File "F:\project_coding\YFZX2\YFspider2\YFspider2\spiders\tibetsun.py", line 96, in deal_reply_nodes
    publish_user_cmt=one_comment.xpath('.//div[contians(@id,"comment")]/div[@class="comment-author"]/span/cite[@class="fn"]/text()').extract()
  File "D:\python_27\lib\site-packages\parsel\selector.py", line 226, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\python_27\lib\site-packages\parsel\selector.py", line 222, in xpath
    **kwargs)
  File "src\lxml\etree.pyx", line 1589, in lxml.etree._Element.xpath (src\lxml\etree.c:61224)
  File "src\lxml\xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__ (src\lxml\etree.c:178763)
  File "src\lxml\xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result (src\lxml\etree.c:177715)
ValueError: XPath error: Unregistered function in .//div[contians(@id,"comment")]/div[@class="comment-author"]/span/cite[@class="fn"]/text()
2018-04-26 16:00:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/opinions/2018/04/26/contrast-in-wests-approach-towards-syria-and-tibet> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tibetsun.com/opinions/2018/04/26/contrast-in-wests-approach-towards-syria-and-tibet>
{'ancestor_id': None,
 'content': u'CHENNAI, India, 26 April 2018 For over seven years, civil war has been going on in Syria between the Syrian government and the rebels. Thousands of people have been killed, many more have been injured, and large numbers of people have left Syria and sought asylum in Europe. In the civil war in Syria, the Syrian government has received support from Russia and Iran directly, and the US and its allies have been directly and indirectly extending support to the rebels. Suddenly, the US and its allies have been expressing deep concern about the plight of innocent citizens in Syria, and saying that chemical weapons have been used by Syrian government in the war against the rebels. The Syrian government has denied that chemical weapons have been used. But the US and its allies insist that chemical weapons have been used, that such weapons have been stockpiled in different locations in Syria, and that innocent people have lost their lives or sustained enormous injuries due to chemical attack on them. Claiming that the US and its allies, including France and the UK, have the responsibility to prevent attacks on innocent citizens in Syria by the so called chemical attacks, the three countries jointly bombed several locations in Syria where chemical weapons are supposed to have been stockpiled. After the bombing of Syria, US and allies complimented themselves that they exhibited a humanitarian gesture by taking steps to save the lives of innocent citizens in Syria. The question now uppermost in the mind of discerning observers is whether these western countries are really so concerned about humanitarian issues and protecting the lives of innocent people. If they are really so concerned, have they gone to the aid of many other innocent people who have suffered atrocities in different parts of the world? While viewing the claims of the US, the UK, France, and other countries such as Australia, Israel and Canada, who are supporting the Syrian bombing as a \u201chumanitarian act\u201d, discerning observers wonder as to why similar humanitarian acts have not been carried out in the case of Tibet, whose people have suffered severe atrocities at the hands of China. Around sixty years back, China occupied Tibet forcefully and mercilessly arrested, killed, or drove out the Tibetans who were protesting against Chinese occupation of their motherland. In the last several decades, China has suppressed the freedom of the people in Tibet, and imposed an iron curtain so that news about happenings in Tibet would not be known to the outside world except the news that Chinese government would approve. The Chinese government has been slowly and systematically destroying the Tibetan culture and traditions and brainwashing the Tibetan youth. US and its allies who say that they have humanitarian considerations and sympathy for suffering people that prompted them to bomb Syria, have simply closed their eyes to the plight of Tibetans who are now forced to live in Chinese-occupied territory under a brutal regime. Instead of condemning China for its acts of aggression in Tibet, US and its allies are bending forward and backward to do business with China, and are taking cautious steps to maintain friendly relations with China, totally ignoring the Chinese acts of aggression in Tibet. Obviously, US and allies adopt such approach towards China, due to China\u2019s economic and military strength, as well as the investment and trade opportunities that China provides them. Most Tibetans now wonder whether the claims of countries like US, UK, and France about their commitment to the cause of liberty and freedom can be believed. Tibetans hoping that the free world would come to their aid now or later to get their fatherland back from Chinese occupation, wish that US and its allies would come forward to this as a humanitarian cause, just as US and its allies claim that they are helping the innocent Syrians . The contrast in approach of US and its allies towards Syria and Tibet is conspicuous and obvious: They will support a humanitarian cause only if it would serve their geopolitical interests.',
 'dislike_count': None,
 'id': 'contrast-in-wests-approach-towards-syria-and-tibet',
 'img_urls': [u'https://media.tibetsun.com/images/opinions/2018/04/contrast-in-wests-approach-towards-syria-and-tibet-pg.jpg'],
 'is_pic': None,
 'like_count': None,
 'like_nodes': None,
 'parent_id': None,
 'publish_time': '2018-04-26 00:00:00',
 'publish_user': None,
 'publish_user_id': None,
 'publish_user_jsonid': None,
 'publish_user_photo': None,
 'read_count': None,
 'reply_count': 0,
 'reply_nodes': None,
 'reproduce_count': None,
 'spider_time': 1524729621438L,
 'title': u'Contrast in West\u2019s approach towards Syria and Tibet',
 'txpath': None,
 'url': 'https://www.tibetsun.com/opinions/2018/04/26/contrast-in-wests-approach-towards-syria-and-tibet',
 'video_urls': None}
2018-04-26 16:00:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/elsewhere/2018/04/13/who-is-pushing-dalai-lama-to-surrender-to-china> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/news/2018/04/20/dalai-lama-to-visit-lithuania-in-june> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/interviews/2018/04/22/the-tibet-question> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/elsewhere/2018/04/13/who-is-pushing-dalai-lama-to-surrender-to-china> (referer: https://www.tibetsun.com/)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python_27\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "F:\project_coding\YFZX2\YFspider2\YFspider2\spiders\tibetsun.py", line 127, in parse_content
    loader1.add_value('reply_nodes',response.selector.xpath('//ol[@class="commentlist"]/li[contains(@class,"comment")]'),deal_reply_nodes)
  File "D:\python_27\lib\site-packages\scrapy\loader\__init__.py", line 70, in add_value
    value = self.get_value(value, *processors, **kw)
  File "D:\python_27\lib\site-packages\scrapy\loader\__init__.py", line 109, in get_value
    value = proc(value)
  File "F:\project_coding\YFZX2\YFspider2\YFspider2\spiders\tibetsun.py", line 96, in deal_reply_nodes
    publish_user_cmt=one_comment.xpath('.//div[contians(@id,"comment")]/div[@class="comment-author"]/span/cite[@class="fn"]/text()').extract()
  File "D:\python_27\lib\site-packages\parsel\selector.py", line 226, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\python_27\lib\site-packages\parsel\selector.py", line 222, in xpath
    **kwargs)
  File "src\lxml\etree.pyx", line 1589, in lxml.etree._Element.xpath (src\lxml\etree.c:61224)
  File "src\lxml\xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__ (src\lxml\etree.c:178763)
  File "src\lxml\xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result (src\lxml\etree.c:177715)
ValueError: XPath error: Unregistered function in .//div[contians(@id,"comment")]/div[@class="comment-author"]/span/cite[@class="fn"]/text()
2018-04-26 16:00:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tibetsun.com/news/2018/04/20/dalai-lama-to-visit-lithuania-in-june>
{'ancestor_id': None,
 'content': u'The Dalai Lama is expected to come to Lithuania in June. The Tibetan spiritual leader is scheduled to visit Lithuania on 13 to 14 June, Ruta Norkute of Tibeto Namai (House of Tibet), a non-governmental organization, told BNS on Thursday. On the first day of his visit, the Dalai Lama will deliver a speech at Vilnius University and will congratulate Lithuania on the centennial of restored statehood, Ervinas Spudys, the university\u2019s spokesman, told BNS. It will be the Dalai Lama\u2019s fourth visit to Lithuania. Lithuanian President Dalia Grybauskaite met with the Tibetan leader during his latest visit back in 2013, thus angering China.',
 'dislike_count': None,
 'id': 'dalai-lama-to-visit-lithuania-in-june',
 'img_urls': [u'https://media.tibetsun.com/images/news/2018/04/dalai-lama-to-visit-lithuania-in-june-pg.jpg'],
 'is_pic': None,
 'like_count': None,
 'like_nodes': None,
 'parent_id': None,
 'publish_time': '2018-04-20 00:00:00',
 'publish_user': None,
 'publish_user_id': None,
 'publish_user_jsonid': None,
 'publish_user_photo': None,
 'read_count': None,
 'reply_count': 0,
 'reply_nodes': None,
 'reproduce_count': None,
 'spider_time': 1524729621829L,
 'title': u'Dalai Lama to visit Lithuania in June',
 'txpath': None,
 'url': 'https://www.tibetsun.com/news/2018/04/20/dalai-lama-to-visit-lithuania-in-june',
 'video_urls': None}
2018-04-26 16:00:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tibetsun.com/interviews/2018/04/22/the-tibet-question>
{'ancestor_id': None,
 'content': u'Despite six decades of Chinese rule, maintaining domestic stability in Tibet is a challenge for Beijing, JNU professor Swaran Singh tells Sapna Singh in an interview. Excerpts: Though China\u2019s economic prowess and garrisons ensure control over Tibet today, continued unrest among Tibetans, both inside China and outside, and especially the iconic presence of the Dalai Lama in India, continues to cause paranoia in China about Tibet not being fully assimilated as a Chinese province.',
 'dislike_count': None,
 'id': 'the-tibet-question',
 'img_urls': [u'https://media.tibetsun.com/images/interviews/2018/04/the-tibet-question-pg.jpg'],
 'is_pic': None,
 'like_count': None,
 'like_nodes': None,
 'parent_id': None,
 'publish_time': '2018-04-22 00:00:00',
 'publish_user': None,
 'publish_user_id': None,
 'publish_user_jsonid': None,
 'publish_user_photo': None,
 'read_count': None,
 'reply_count': 0,
 'reply_nodes': None,
 'reproduce_count': None,
 'spider_time': 1524729621871L,
 'title': u'The Tibet Question',
 'txpath': None,
 'url': 'https://www.tibetsun.com/interviews/2018/04/22/the-tibet-question',
 'video_urls': None}
2018-04-26 16:00:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/health/2017/09/21/tibetan-yoga-may-improve-chemotherapy-related-fatigue> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tibetsun.com/health/2017/09/21/tibetan-yoga-may-improve-chemotherapy-related-fatigue>
{'ancestor_id': None,
 'content': u'Attending at least two Tibetan yoga sessions per week may improve chemotherapy-related fatigue among patients with breast cancer, according to research published in Cancer . [ ref ] Previous study suggests that yoga may be beneficial for patients receiving chemotherapy, which can cause sleep disturbance and fatigue. Yet few of these studies include controls and long-term follow-up. For this randomized study, researchers evaluated whether, among patients with breast cancer who were receiving or had received chemotherapy, Tibetan yoga would improve fatigue and mitigate sleep disturbance more effectively than an active stretching program or a usual care control group. Of 933 eligible patients, 352 were randomly assigned, and 227 were included in this analysis (74 in the yoga group, 68 in the stretching group, and 85 in the control group). Baseline characteristics were similar between the groups. Although no significant differences were noted for sleep disturbance or fatigue between any of the groups, patients who practiced yoga at least twice a week had improved sleep compared with the control group at 3 and 6 months post-intervention. The stretching group, for unknown reasons, was the only group to not have improved fatigue over time. The authors concluded that these results \u201csuggest that it is ideal to have [more than] 4 in-person sessions to improve patient outcomes, whereas to our knowledge the minimum dose necessary to improve outcomes was previously unknown.\u201d',
 'dislike_count': None,
 'id': 'tibetan-yoga-may-improve-chemotherapy-related-fatigue',
 'img_urls': None,
 'is_pic': None,
 'like_count': None,
 'like_nodes': None,
 'parent_id': None,
 'publish_time': '2017-09-21 00:00:00',
 'publish_user': None,
 'publish_user_id': None,
 'publish_user_jsonid': None,
 'publish_user_photo': None,
 'read_count': None,
 'reply_count': 0,
 'reply_nodes': None,
 'reproduce_count': None,
 'spider_time': 1524729622898L,
 'title': u'Tibetan Yoga may improve chemotherapy-related fatigue',
 'txpath': None,
 'url': 'https://www.tibetsun.com/health/2017/09/21/tibetan-yoga-may-improve-chemotherapy-related-fatigue',
 'video_urls': None}
2018-04-26 16:00:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/news/2018/04/14/india-outrage-mounts-over-gang-rape-murder-of-8-year-old> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tibetsun.com/news/2018/04/14/india-outrage-mounts-over-gang-rape-murder-of-8-year-old>
{'ancestor_id': None,
 'content': u'India\u2019s Prime Minister Narendra Modi on Friday promised justice after nationwide outrage mounted over the brutal gang rape and murder of an eight-year-old-girl. Demonstrations were held in New Delhi and other cities as horrific details emerged of the murder of the Muslim girl, who was repeatedly raped while being held for five days in the city of Kathua in Jammu, including at a Hindu temple. \u201cThe incidents being discussed for the last two days are definitely shameful for any civil society. We are all ashamed as a society and a country,\u201d Modi said in a speech in New Delhi. \u201cI want to assure the country that no criminal will be spared, justice will be done and completed.\u201d Earlier, the country\u2019s women\u2019s minister called for the death penalty for child rapists in a video message posted online. \u201cI have been deeply, deeply disturbed by the rape case in Kathua and all the recent rape cases that have happened on children,\u201d Maneka Gandhi, the women and children\u2019s minister, said on Twitter. Gandhi said her ministry would seek an amendment to India\u2019s Protection of Children from Sexual Offences Act, \u201casking for the death penalty for rape on children below 12 years\u201d. The Kathua killing has shaken India in a way reminiscent of the fatal gang rape of a Delhi student on a bus in 2012 that made headlines around the world. Rahul Gandhi, leader of the opposition Congress party, led a candlelight march late Thursday to the India Gate monument in Delhi \u2014 the site of mass protests after the 2012 attack \u2014 to highlight the \u201cunimaginable brutality\u201d of the latest killing. \u201cLike millions of Indians my heart hurts,\u201d Gandhi said at the midnight rally. \u201cIndia simply cannot continue to treat its women the way it does.\u201d Vikramaditya Singh, who joined protestors at India Gate later Friday, said deep reforms were needed to improve women\u2019s rights in India. \u201cThe women in this country are the victims of these crimes. Besides taking action in this case, we need to look at the\u2026 upbringing and education of men in our society,\u201d Singh told AFP. Eight people have been arrested over the killing, including four police officers and a minor. All are Hindus. The victim, whose identity was protected by a court order Friday, was murdered in January in the northern state of Jammu and Kashmir. According to the charge sheet, she was abducted by the minor and an accomplice. The girl was forced to take sedatives and during five days in a shed and then a Hindu temple, she was repeatedly raped by the juvenile and different men, including a police constable. She was finally strangled and beaten with a stone. According to the charge sheet, one of the attackers raped her just before she died. Jammu and Kashmir is India\u2019s only Muslim-majority state, but the Jammu region in the south, where the rape and murder took place, is Hindu-dominated. The case has heightened fears of communal tensions in the region. Muslim activists have demanded action against what they see as a crime against their community while some right-wing Hindu groups have argued that the accused were unfairly charged. This week, a crowd of Hindu lawyers tried to stop police from entering a court to file charges against the accused men. Separately, a senior lawmaker in Uttar Pradesh state faces arrest over the rape of a 17-year-old woman. The lawmaker is from Prime Minister Modi\u2019s Bharatiya Janata Party. The alleged attack occurred last year but only started making headlines again after the woman tried to set herself on fire outside the Uttar Pradesh chief minister\u2019s residence last weekend. High-profile names from the world of cinema and cricket joined the outrage over the Jammu crime in a country were nearly 40,000 rape cases are reported every year, according to official figures. \u201cWhat is happening to the world we live in???\u201d Bollywood star Anushka Sharma, who is married to Indian cricket captain Virat Kohli, wrote on Twitter. \u201cThese people should be given the most severe punishment there is! Where are we heading as humanity? Shaken to my core.\u201d Cricketer Gautam Gambhir blamed India\u2019s \u201cstinking systems\u201d for what some have described as a rape epidemic. \u201cCome on \u2018Mr System\u2019, show us if you have the balls to punish the perpetrators, I challenge you,\u201d he tweeted.',
 'dislike_count': None,
 'id': 'india-outrage-mounts-over-gang-rape-murder-of-8-year-old',
 'img_urls': [u'https://media.tibetsun.com/images/news/2018/04/india-outrage-mounts-over-gang-rape-murder-of-8-year-old-pg.jpg'],
 'is_pic': None,
 'like_count': None,
 'like_nodes': None,
 'parent_id': None,
 'publish_time': '2018-04-14 00:00:00',
 'publish_user': None,
 'publish_user_id': None,
 'publish_user_jsonid': None,
 'publish_user_photo': None,
 'read_count': None,
 'reply_count': 0,
 'reply_nodes': None,
 'reproduce_count': None,
 'spider_time': 1524729623622L,
 'title': u'India outrage mounts over gang rape, murder of 8-year-old',
 'txpath': None,
 'url': 'https://www.tibetsun.com/news/2018/04/14/india-outrage-mounts-over-gang-rape-murder-of-8-year-old',
 'video_urls': None}
2018-04-26 16:00:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/news/2018/04/15/shoton-festival-starts-from-20th-12-opera-troupes-to-perform> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/news/2018/04/15/shoton-festival-starts-from-20th-12-opera-troupes-to-perform> (referer: https://www.tibetsun.com/)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python_27\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "F:\project_coding\YFZX2\YFspider2\YFspider2\spiders\tibetsun.py", line 127, in parse_content
    loader1.add_value('reply_nodes',response.selector.xpath('//ol[@class="commentlist"]/li[contains(@class,"comment")]'),deal_reply_nodes)
  File "D:\python_27\lib\site-packages\scrapy\loader\__init__.py", line 70, in add_value
    value = self.get_value(value, *processors, **kw)
  File "D:\python_27\lib\site-packages\scrapy\loader\__init__.py", line 109, in get_value
    value = proc(value)
  File "F:\project_coding\YFZX2\YFspider2\YFspider2\spiders\tibetsun.py", line 96, in deal_reply_nodes
    publish_user_cmt=one_comment.xpath('.//div[contians(@id,"comment")]/div[@class="comment-author"]/span/cite[@class="fn"]/text()').extract()
  File "D:\python_27\lib\site-packages\parsel\selector.py", line 226, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\python_27\lib\site-packages\parsel\selector.py", line 222, in xpath
    **kwargs)
  File "src\lxml\etree.pyx", line 1589, in lxml.etree._Element.xpath (src\lxml\etree.c:61224)
  File "src\lxml\xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__ (src\lxml\etree.c:178763)
  File "src\lxml\xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result (src\lxml\etree.c:177715)
ValueError: XPath error: Unregistered function in .//div[contians(@id,"comment")]/div[@class="comment-author"]/span/cite[@class="fn"]/text()
2018-04-26 16:00:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/news/2018/04/22/indias-modi-to-visit-china-this-week-as-rapprochement-gathers-pace> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/news/2018/04/22/indias-modi-to-visit-china-this-week-as-rapprochement-gathers-pace> (referer: https://www.tibetsun.com/)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python_27\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "F:\project_coding\YFZX2\YFspider2\YFspider2\spiders\tibetsun.py", line 127, in parse_content
    loader1.add_value('reply_nodes',response.selector.xpath('//ol[@class="commentlist"]/li[contains(@class,"comment")]'),deal_reply_nodes)
  File "D:\python_27\lib\site-packages\scrapy\loader\__init__.py", line 70, in add_value
    value = self.get_value(value, *processors, **kw)
  File "D:\python_27\lib\site-packages\scrapy\loader\__init__.py", line 109, in get_value
    value = proc(value)
  File "F:\project_coding\YFZX2\YFspider2\YFspider2\spiders\tibetsun.py", line 96, in deal_reply_nodes
    publish_user_cmt=one_comment.xpath('.//div[contians(@id,"comment")]/div[@class="comment-author"]/span/cite[@class="fn"]/text()').extract()
  File "D:\python_27\lib\site-packages\parsel\selector.py", line 226, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\python_27\lib\site-packages\parsel\selector.py", line 222, in xpath
    **kwargs)
  File "src\lxml\etree.pyx", line 1589, in lxml.etree._Element.xpath (src\lxml\etree.c:61224)
  File "src\lxml\xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__ (src\lxml\etree.c:178763)
  File "src\lxml\xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result (src\lxml\etree.c:177715)
ValueError: XPath error: Unregistered function in .//div[contians(@id,"comment")]/div[@class="comment-author"]/span/cite[@class="fn"]/text()
2018-04-26 16:00:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/news_you_witness/2018/04/19/mps-call-on-liverpool-fc-to-terminate-deal-with-chinese-water-company> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tibetsun.com/news_you_witness/2018/04/19/mps-call-on-liverpool-fc-to-terminate-deal-with-chinese-water-company>
{'ancestor_id': None,
 'content': u'Today 25 Members of Parliament from across the United Kingdom and political spectrum urged Liverpool Football Club to scrap its controversial deal with Chinese company, Tibet Water Resources Limited. The 25 MPs, which represent constituencies from as far North as Dundee and as far South as East Worthing and Shoreham, called on the club to end its partnership and reaffirm its commitment to the promotion and protection of human rights. The deal, signed on 24 July 2017, saw Tibet Water become Liverpool FC\u2019s official regional water partner in China and offers the company a range of promotional and marketing rights. The 25 parliamentarians expressed their concern that the deal \u201cis not consistent\u201d with the values promoted in the club\u2019s human rights framework and have called on Liverpool FC to ensure due diligence standards have been met and that its business partners commit to respecting human rights. In the letter, MPs also echoed the sentiment expressed by Tibet organisations that Tibet Water is only able to operate in Tibet as a result of the Chinese occupation and the human rights violations that uphold it and called on Liverpool FC \u201cto terminate the agreement.\u201d In China-occupied Tibet, the Chinese government severely restricts all fundamental rights and freedoms, including freedoms of association, expression, and religion. Tibetans continue to face arbitrary arrest, torture and indefinite detention. Tibetan activists, writers and pro-democracy advocates remain subject to long terms of imprisonment under severe laws nominally drawn up to counter \u201cterrorism\u201d or \u201ccyber security\u201d. MPs from the Liverpool area have also joined the campaign, including Stephen Twigg MP for Liverpool West Derby and Dan Carden MP for Liverpool Walton, who are understood to have written to the club expressing their concern about the partnership. Tibet advocacy groups in the UK have similarly written to John W Henry and Liverpool FC\u2019s directors to alert them to the negative effects of a deal with a company exploiting resources in Tibet \u2014 although over six months on, a response has yet to be received. Tibet organisations, including the International Tibet Network, Free Tibet and Tibet Society, as well as international consumer group SumOfUs, launched a campaign calling for an end to the deal in October 2017. Nearly 90,000 people have since contacted Liverpool FC, urging them to end to their sponsorship with Tibet Water and stand up for the rights and freedoms of Tibetans. Gloria Montgomery, Head of Advocacy and Campaigns at Tibet Society, said that politicians from across the political spectrum care deeply about the Tibetan cause and are committed to ensuring brands and companies respect human rights when carrying out their business practices. John Jones, Campaigns and Communications Manager at Free Tibet said, \u201cSince Liverpool\u2019s directors signed this dangerous deal last year, it has encountered strong opposition from Tibetans and Liverpool fans, who were aware of the risks it posed to their country and their club \u2026. Their voices must be listened to, and the deal dropped.\u201d Sondhya Gupta, Senior Campaigner at SumOfUs, said, \u201cFans don\u2019t want to see their club lend legitimacy to the Chinese military occupation of Tibet by partnering with a corporation that owes its profits to the torture and repression of the Tibetan people.\u201d More information on Liverpool FC\u2019s deal with Tibet Water and ways to take action  can be found here',
 'dislike_count': None,
 'id': 'mps-call-on-liverpool-fc-to-terminate-deal-with-chinese-water-company',
 'img_urls': None,
 'is_pic': None,
 'like_count': None,
 'like_nodes': None,
 'parent_id': None,
 'publish_time': '2018-04-19 00:00:00',
 'publish_user': None,
 'publish_user_id': None,
 'publish_user_jsonid': None,
 'publish_user_photo': None,
 'read_count': None,
 'reply_count': 0,
 'reply_nodes': None,
 'reproduce_count': None,
 'spider_time': 1524729624249L,
 'title': u'MPs call on Liverpool FC to terminate deal With Chinese water company',
 'txpath': None,
 'url': 'https://www.tibetsun.com/news_you_witness/2018/04/19/mps-call-on-liverpool-fc-to-terminate-deal-with-chinese-water-company',
 'video_urls': None}
2018-04-26 16:00:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/news/2018/04/21/north-korea-says-will-stop-nuclear-tests-scrap-test-site> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/news/2018/04/25/indian-court-jails-popular-guru-for-life-over-teen-rape> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/archives/health> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/about> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.tibetsun.com/news/2018/04/21/north-korea-says-will-stop-nuclear-tests-scrap-test-site>
{'ancestor_id': None,
 'content': u'North Korea will immediately suspend nuclear and missile tests and scrap its nuclear test site and instead pursue economic growth and peace, the North\u2019s state media said on Saturday, ahead of planned summits with South Korea and the United States. North Korean leader Kim Jong Un said his country no longer needed to conduct nuclear tests or intercontinental ballistic missile tests because it had completed its goal of developing nuclear weapons, the Korean Central News Agency (KCNA) said. North Korea said that to create an \u201cinternational environment favorable\u201d for its economy, it would \u201cfacilitate close contact and active dialogue\u201d with neighboring countries and the international community. It was the first time Kim directly addressed his position on North Korea\u2019s nuclear weapons programs ahead of planned summits with South Korean President Moon Jae-in next week and with US President Donald Trump in late May or early June. The pledge to halt the development of nuclear weapons, initiated by his grandfather and continued by his father, would mean a significant reversal for the young, third-generation leader, now 34, who has staked his security on his nuclear arsenal and spent years celebrating such weapons as an integral part of his regime\u2019s legitimacy and power. A testing freeze and commitment to close a test site alone would fall short of Washington\u2019s demand that Pyongyang completely dismantle all of its nuclear weapons and missiles. But announcing the concessions now, rather than during summit meetings, shows Kim is serious about denuclearisation talks, experts say. \u201cThe northern nuclear test ground of the DPRK will be dismantled to transparently guarantee the discontinuance of the nuclear test,\u201d KCNA said after Kim convened a plenary session of the Central Committee of the ruling Worker\u2019s Party on Friday. The North\u2019s official name is the Democratic People\u2019s Republic of Korea (DPRK). The Pyunggye-ri site in northern North Korea is its only known nuclear test site, where all of its six underground tests were conducted, including the last, its largest-ever detonation, in September. \u201cWe will concentrate all efforts on building a powerful socialist economy and markedly improving the standard of people\u2019s living through the mobilization of all human and material resources of the country,\u201d KCNA said. Trump welcomed the statement and said he looked forward to a summit with Kim. \u201cNorth Korea has agreed to suspend all Nuclear Tests and close up a major test site. This is very good news for North Korea and the World \u2014 big progress! Look forward to our Summit,\u201d Trump said on Twitter. South Korea said the North\u2019s decision signified \u201cmeaningful\u201d progress toward denuclearisation of the Korean peninsula and would create favourable conditions for successful meetings with it and the United States. Japanese Prime Minister Shinzo Abe said he welcomed North Korea\u2019s statement but it must lead to verifiable denuclearisation. \u201cThis announcement is forward motion that I\u2019d like to welcome,\u201d Abe told reporters. \u201cBut what\u2019s important is that this leads to complete, verifiable denuclearisation. I want to emphasize this.\u201d The United States, Japan and South Korea have historically been the main targets of North Korea\u2019s anger. \u201cWe\u2019re all looking for evidence that Kim is really serious about negotiations, and announcements like this certainly suggest he is, and that he is trying to make clear to the world that he is,\u201d said David Wright, co-director of the Global Security Program at the Union of Concerned Scientists. North Korea has said its nuclear and missile programs are necessary deterrents against US hostility. It has conducted numerous missile tests with the aim of being able to hit the United States with a nuclear bomb. The tests and escalating rhetoric between Trump and Kim raised fears of war until, in a New Year\u2019s speech, the North Korean leader called for reduced military tensions. He later improved ties with South Korea and sent a delegation to the Winter Olympics in the South in February. Nam Sung-wook, professor of North Korean Studies at Korea University in Seoul, said it was \u201csensational\u201d that Kim had personally declared plans to suspend nuclear development, but added that his remarks left a number of questions. \u201cIt still does not seem clear if it means whether the North will just not pursue further development of its nuclear programs in the future, or whether they will completely shut down \u2018all\u2019 nuclear facilities. And what are they going to do with their existing nuclear weapons?\u201d Nam said. South Korean President Moon said on Thursday North Korea had expressed a commitment to \u201ccomplete denuclearisation\u201d of the Korean peninsula, and had not attached conditions, but Washington had remained wary and vowed to maintain \u201cmaximum pressure\u201d on Pyongyang. The United States said on Thursday that in the run-up to Trump\u2019s planned summit with Kim, countries should continue to put financial and diplomatic pressure on Pyongyang to surrender its banned nuclear weapons. Many US officials and experts doubt Kim\u2019s sincerity about denuclearizing, viewing the recent flurry of diplomacy as a ploy to win relief from economic sanctions. UN Security Council sanctions imposed on North Korea after its first nuclear test in 2006 and extended over the past decade have aimed to deny it a considerable amount of international trade, banning critical exports such as coal, iron ore, seafood, textile while limiting oil imports. That has threatened the policy of byungjin \u2014 simultaneous military and economic development \u2014 that Kim Jong Un has adopted since taking power in late 2011. \u201cEasing tensions and cooperating with the international community is critical if Kim wanted to advance the economy,\u201d said Cheong Seong-chang, a senior fellow at the Sejong Institute think-tank south of Seoul. Koh Yu-hwan, professor of North Korean Studies at Dongguk University in Seoul, said he did not believe Pyongyang was ready to give up its existing nuclear weapons and missiles. \u201cKim is just saying that now that the nuclear development is complete, he will put all the efforts toward building an economy,\u201d Koh said.',
 'dislike_count': None,
 'id': 'north-korea-says-will-stop-nuclear-tests-scrap-test-site',
 'img_urls': [u'https://media.tibetsun.com/images/news/2018/04/north-korea-says-will-stop-nuclear-tests-scrap-test-site-pg.jpg'],
 'is_pic': None,
 'like_count': None,
 'like_nodes': None,
 'parent_id': None,
 'publish_time': '2018-04-21 00:00:00',
 'publish_user': None,
 'publish_user_id': None,
 'publish_user_jsonid': None,
 'publish_user_photo': None,
 'read_count': None,
 'reply_count': 0,
 'reply_nodes': None,
 'reproduce_count': None,
 'spider_time': 1524729624645L,
 'title': u'North Korea says will stop nuclear tests, scrap test site',
 'txpath': None,
 'url': 'https://www.tibetsun.com/news/2018/04/21/north-korea-says-will-stop-nuclear-tests-scrap-test-site',
 'video_urls': None}
2018-04-26 16:00:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/news/2018/04/25/indian-court-jails-popular-guru-for-life-over-teen-rape> (referer: https://www.tibetsun.com/)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python_27\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python_27\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "F:\project_coding\YFZX2\YFspider2\YFspider2\spiders\tibetsun.py", line 127, in parse_content
    loader1.add_value('reply_nodes',response.selector.xpath('//ol[@class="commentlist"]/li[contains(@class,"comment")]'),deal_reply_nodes)
  File "D:\python_27\lib\site-packages\scrapy\loader\__init__.py", line 70, in add_value
    value = self.get_value(value, *processors, **kw)
  File "D:\python_27\lib\site-packages\scrapy\loader\__init__.py", line 109, in get_value
    value = proc(value)
  File "F:\project_coding\YFZX2\YFspider2\YFspider2\spiders\tibetsun.py", line 96, in deal_reply_nodes
    publish_user_cmt=one_comment.xpath('.//div[contians(@id,"comment")]/div[@class="comment-author"]/span/cite[@class="fn"]/text()').extract()
  File "D:\python_27\lib\site-packages\parsel\selector.py", line 226, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\python_27\lib\site-packages\parsel\selector.py", line 222, in xpath
    **kwargs)
  File "src\lxml\etree.pyx", line 1589, in lxml.etree._Element.xpath (src\lxml\etree.c:61224)
  File "src\lxml\xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__ (src\lxml\etree.c:178763)
  File "src\lxml\xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result (src\lxml\etree.c:177715)
ValueError: XPath error: Unregistered function in .//div[contians(@id,"comment")]/div[@class="comment-author"]/span/cite[@class="fn"]/text()
2018-04-26 16:00:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/archives/opinions> from <GET https://www.tibetsun.com/archives/opinions/>
2018-04-26 16:00:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/weather> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/contact> from <GET https://www.tibetsun.com/contact/>
2018-04-26 16:00:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/archives/news> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/archives/features> from <GET https://www.tibetsun.com/archives/features/>
2018-04-26 16:00:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/disclaimer> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/archives/interviews> from <GET https://www.tibetsun.com/archives/interviews/>
2018-04-26 16:00:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/about> from <GET https://www.tibetsun.com/about/>
2018-04-26 16:00:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/archives/features> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/archives/opinions> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/archives/interviews> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/contact> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/archives/have_your_say> from <GET https://www.tibetsun.com/archives/have_your_say/>
2018-04-26 16:00:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/week-in-photos> from <GET https://www.tibetsun.com/week-in-photos/>
2018-04-26 16:00:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/archives/news> from <GET https://www.tibetsun.com/archives/news/>
2018-04-26 16:00:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/archives/tech_news> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/copyright> from <GET https://www.tibetsun.com/copyright/>
2018-04-26 16:00:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/elections/election-2016-official-final-round-results> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/archives/have_your_say> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/tech_news> from <GET https://www.tibetsun.com/tech_news/>
2018-04-26 16:00:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/archives/news_you_witness> from <GET https://www.tibetsun.com/archives/news_you_witness/>
2018-04-26 16:00:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/archives/elsewhere> from <GET https://www.tibetsun.com/archives/elsewhere/>
2018-04-26 16:00:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/letters-to-the-editor> from <GET https://www.tibetsun.com/letters-to-the-editor/>
2018-04-26 16:00:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tibetsun.com/health> from <GET https://www.tibetsun.com/health/>
2018-04-26 16:00:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/advertise> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/science/2017/10/13/nasa-satellite-sees-overheated-tropical-forests-oozing-with-carbon-dioxide> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/1908> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/science/2017/10/13/nasa-satellite-sees-overheated-tropical-forests-oozing-with-carbon-dioxide> (referer: https://www.tibetsun.com/)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
GeneratorExit
2018-04-26 16:00:30 [scrapy.core.scraper] ERROR: Error processing {'content': u'NASA\u2019s latest carbon dioxide-mapping satellite has detected a dramatic spike in the amount of the greenhouse gas in the atmosphere, measuring the largest annual increase Earth has seen in at least 2,000 years. The cause? Overheating of three major tropical forest regions across the globe. NASA\u2019s Orbiting Carbon Observatory (OCO-2), is one of several satellites that collect greenhouse gas emissions data, and researcher Junjie Liu of NASA\u2019s Jet Propulsion Laboratory (JPL) in Pasadena, California, used this probe\u2019s data to uncover how much \u2014 or in this case, how little \u2014 carbon dioxide (CO2) was absorbed out of the atmosphere by Earth\u2019s tropical forests. NASA presented new research findings with a teleconference on Oct 12 that featured Liu alongside Michael Freilich, director of the Earth Science Division at NASA headquarters in Washington, D.C.; Annmarie Eldering, the OCO-2 deputy project scientist at JPL; and Scott Denning, professor of atmospheric science at Colorado State University. [CO2 Satellite: NASA\u2019s Orbiting Carbon Observatory-2 Mission in Photos] OCO-2 has given scientists a \u201crevolutionary\u201d new way to understand the effects of droughts and heat on tropical rainforests, Freilich said in the briefing. The remoteness of these regions, their lack of field stations and the distorting effect of thunderstorms on land-based measurements of CO2 make the OCO-2 satellite an important and unique tool for monitoring the movement and increase of this greenhouse gas, he added. NASA launched OCO-2 in 2014 just in time for the record spike of global atmospheric CO2 that occurred between 2015 and 2016. \u201cIn both 2015 and 2016, OCO-2 and the National Oceanic and Atmospheric Administration (NOAA) measured the largest annual increases in atmospheric carbon dioxide in at least 2,000 years,\u201d Eldering said during the briefing. Using OCO-2 data, Liu quantified that \u201cin total, the three tropical land regions released at least 2.5 gigatons more of carbon into the atmosphere than they did in 2011,\u201d or about a 50 percent increase, he said during the briefing. Droughts in Earth\u2019s tropical forests result from the El Ni\xf1o climate cycle, and El Ni\xf1o-like weather conditions are expected to become more extreme in the coming years, NASA scientists said in the briefing. This change will make droughts more severe in tropical forests, which could cause even bigger spikes in CO2 levels in the near future. As plants experience warmer and drier conditions, they\u2019re more likely to dry out and rot, producing more CO2 instead of removing it from the atmosphere like healthy plants do. Without enough plants to perform photosynthesis and filter CO2 out of the air, the tropical forests will not be able to soak up as much of the greenhouse gas emissions that are increasing global temperatures across the planet, NASA scientists said. Eldering explained that OCO-2 takes about 100,000 direct and daily measurements of CO2 over the tropical forest regions of South America (like the Amazon rainforest), the tropical forests of Africa and the tropical region of Asia surrounding Indonesia. As the OCO-2 satellite orbits Earth from one pole to the other, measuring CO2 levels around the world, it also senses the rate of photosynthesis by detecting fluorescent chlorophyll in vegetation on the ground. These measurements help scientists produce models of plant decomposition rates across the globe. \u201cThe OCO-2 satellite allowed our team to quantify how the net exchange of carbon between land and atmosphere in each tropical region was affected by the 2015-2016 El Ni\xf1o,\u201d Liu said. \u201cTo put that in perspective,\u201d Eldering added, \u201cthat is equal to almost a third of all carbon dioxide emitted from human activities during that same time period.\u201d The Amazon basin, according to Liu\u2019s findings, experienced the most severe drought in 30 years. Precipitation data from satellite measurements and terrestrial rain data revealed that plants were decomposing faster in the tropical forests in Africa, thereby releasing more CO2 and absorbing less of it. The heat from forest fires in Indonesia \u2014 some of which were human-made \u2014 also increased tropical Asia\u2019s carbon dioxide release.',
 'id': 'nasa-satellite-sees-overheated-tropical-forests-oozing-with-carbon-dioxide',
 'img_urls': [u'https://media.tibetsun.com/images/science/2017/10/nasa-satellite-sees-overheated-tropical-forests-oozing-with-carbon-dioxide-pg.jpg'],
 'publish_time': '2017-10-13 00:00:00',
 'reply_count': 0,
 'spider_time': 1524729630146L,
 'title': u'NASA satellite sees overheated tropical forests oozing with carbon dioxide',
 'url': 'https://www.tibetsun.com/science/2017/10/13/nasa-satellite-sees-overheated-tropical-forests-oozing-with-carbon-dioxide'}
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\python\threadpool.py", line 250, in inContext
    result = inContext.theWork()
  File "D:\python_27\lib\site-packages\twisted\python\threadpool.py", line 266, in <lambda>
    inContext.theWork = lambda: context.call(ctx, func, *args, **kw)
  File "D:\python_27\lib\site-packages\twisted\python\context.py", line 122, in callWithContext
    return self.currentContext().callWithContext(ctx, func, *args, **kw)
  File "D:\python_27\lib\site-packages\twisted\python\context.py", line 85, in callWithContext
    return func(*args,**kw)
  File "D:\python_27\lib\site-packages\scrapy_redis\pipelines.py", line 66, in _process_item
    self.server.rpush(key, data)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1388, in rpush
    return self.execute_command('RPUSH', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled error in Deferred:
2018-04-26 16:00:30 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "D:\python_27\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1600, in sadd
    return self.execute_command('SADD', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/1908> (referer: https://www.tibetsun.com/archives/health)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
GeneratorExit
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled error in Deferred:
2018-04-26 16:00:30 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "D:\python_27\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1600, in sadd
    return self.execute_command('SADD', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/1959> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/1959> (referer: https://www.tibetsun.com/archives/health)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
GeneratorExit
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled error in Deferred:
2018-04-26 16:00:30 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "D:\python_27\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1600, in sadd
    return self.execute_command('SADD', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/1964> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/1947> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/1964> (referer: https://www.tibetsun.com/archives/health)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
GeneratorExit
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled error in Deferred:
2018-04-26 16:00:30 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "D:\python_27\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1600, in sadd
    return self.execute_command('SADD', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/1947> (referer: https://www.tibetsun.com/archives/health)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
GeneratorExit
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled error in Deferred:
2018-04-26 16:00:30 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "D:\python_27\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1600, in sadd
    return self.execute_command('SADD', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/copyright> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/1998> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/1951> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/losar-dinner-feast> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/copyright> (referer: https://www.tibetsun.com/)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
GeneratorExit
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled error in Deferred:
2018-04-26 16:00:31 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "D:\python_27\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1600, in sadd
    return self.execute_command('SADD', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/1998> (referer: https://www.tibetsun.com/archives/health)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
GeneratorExit
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled error in Deferred:
2018-04-26 16:00:31 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "D:\python_27\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1600, in sadd
    return self.execute_command('SADD', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/1951> (referer: https://www.tibetsun.com/archives/health)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
GeneratorExit
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled error in Deferred:
2018-04-26 16:00:31 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "D:\python_27\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1600, in sadd
    return self.execute_command('SADD', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/week-in-photos/losar-dinner-feast> (referer: https://www.tibetsun.com/week-in-photos)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
GeneratorExit
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled error in Deferred:
2018-04-26 16:00:31 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "D:\python_27\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1600, in sadd
    return self.execute_command('SADD', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/dalai-lama-laughs> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tibetsun.com/week-in-photos/dalai-lama-laughs> (referer: https://www.tibetsun.com/week-in-photos)
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
GeneratorExit
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled error in Deferred:
2018-04-26 16:00:31 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "D:\python_27\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "D:\python_27\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "D:\python_27\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "D:\python_27\lib\site-packages\redis\client.py", line 1600, in sadd
    return self.execute_command('SADD', name, *values)
  File "D:\python_27\lib\site-packages\redis\client.py", line 668, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
ResponseError: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.
2018-04-26 16:00:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/tech_news> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:32 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/losar-revellers-dance> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:32 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\python_27\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "D:\python_27\lib\site-packages\scrapy\crawler.py", line 285, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1243, in run
    self.mainLoop()
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 1252, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\python_27\lib\site-packages\twisted\internet\base.py", line 878, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\python_27\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\python_27\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\python_27\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\python_27\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\python_27\lib\site-packages\redis\client.py", line 2879, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2775, in _execute_transaction
    self.immediate_execute_command('DISCARD')
  File "D:\python_27\lib\site-packages\redis\client.py", line 2715, in immediate_execute_command
    return self.parse_response(conn, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 2838, in parse_response
    self, connection, command_name, **options)
  File "D:\python_27\lib\site-packages\redis\client.py", line 680, in parse_response
    response = connection.read_response()
  File "D:\python_27\lib\site-packages\redis\connection.py", line 629, in read_response
    raise response
redis.exceptions.ResponseError: DISCARD without MULTI

2018-04-26 16:00:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/members-read-resolution> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/dalai-lama-group-photo> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/archives/elsewhere> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/health> (referer: https://www.tibetsun.com/)
2018-04-26 16:00:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/members-read-resolution-2> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/dalai-lama-with-thai-monk> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/candles-for-tsekho-tukchak> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/dalai-lama-speaks-to-tourists> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/children-play-during-2018-losar> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/dalai-lama-speaks-to-journalists> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/lhagyari-namgyal-dolkar-speaks> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/lobsang-sangay-listens-to-reading> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/lobsang-sangay-speaks-during-event> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/lobsang-sangay-speaks-on-10-march> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/dalai-lama-embraces-naren-chandra-das> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/lugtsang-gyari-thar-reads-resolution> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/kyinzom-dhongdue-listens-to-reading> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/khenpo-sonam-tenphel-delivering-opening-remarks> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/parliament-sing-tibetan-national-anthem> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/page/2> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/page/4> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/page/3> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/page/5> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/page/15> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/page/10> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/week-in-photos/page/20> (referer: https://www.tibetsun.com/week-in-photos)
2018-04-26 16:00:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2007> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2009> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2014> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2008> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2010> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2011> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2015> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2012> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2013> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2016> (referer: https://www.tibetsun.com/archives/health)
2018-04-26 16:00:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/tag/india> (referer: https://www.tibetsun.com/news/2018/04/14/india-outrage-mounts-over-gang-rape-murder-of-8-year-old)
2018-04-26 16:00:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tibetsun.com/2017> (referer: https://www.tibetsun.com/archives/health)

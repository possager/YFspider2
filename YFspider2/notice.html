<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>爬虫编写注意事项</title>
</head>
<body>


<div class="tchrd">
    <h1>
        编写爬虫过程中遇到的问题
    </h1>
    <div>
        <a>
            <h4>
                统一记录格式：应当包含网站链接，爬虫名称，爬虫时间，启动方式，中间遇到的问题
            </h4>
        </a>
    </div>
    <a>
        <h3>
            tchrd
        </h3>
        <p>
        tchrd网站中的默认启动方式，通过往redis中传递url来启动爬虫
        lpush tchrd:url http://tchrd.org/chinese/%E8%A5%BF%E8%97%8F%E4%B8%80%E5%BA%A7%E5%B7%A8%E5%A4%A7%E7%9A%84%E7%9B%91%E7%8B%B1%E8%A5%BF%E8%97%8F%E4%BA%BA%E6%9D%83%E4%B8%8E%E6%B0%91%E4%B8%BB%E4%BF%83%E8%BF%9B%E4%B8%AD%E5%BF%83%E5%8F%91%E5%B8%83/
        这样启动的网站爬虫爬取不完整。
        还可以添加
        lpush tchrd:url http://tchrd.org/chinese/1999-%E8%A5%BF%E8%97%8F%E4%BA%BA%E6%9D%83%E6%8A%A5%E5%91%8A-%E6%91%98%E8%A6%81/
        但是效果也不完整
        </p>
        <p>
            时间：2018-01-05
        </p>
    </a>

    <a>
        <h3>
            studentsforafreetibet
        </h3>
        <p>
            这个网站里边的内容十分杂乱，目前打算只抓取media板块中的内容。
        </p>
        <p>
            时间：2018-01-04
        </p>
    </a>

    <a>
        <h3>
            tibetonline.tv
        </h3>
        <p>
            这个网站里边的内容都是视频，暂时没抓
        </p>
        <p>
            时间：2018-01-08
        </p>
    </a>
    <a>
        <h3>
            tibetanyouthcongress
        </h3>
        <p>
            今天突然发现如果id用md5的话，那么这个id的意义也就不在了
        </p>
        <p>
            时间：2018-01-08
        </p>
    </a>
    <a>
        <h3>
            rtycnynj
        </h3>
        <p>
            这个网站失效了
        </p>
        <p>
            时间：2018-01-08
        </p>
    </a>
    <a>
        <h3>
            tibetanwomen
        </h3>
        <p>
            这个网站中研究出来了很多东西
        </p>
        <p>
            时间：2018-01-08
        </p>
    </a>
    <a>
        <h3>
            tibetswiss
        </h3>
        <p>
            这个网站全是藏文，我把左上角的几个模块都添加进去了,分别是
            <a>
                europe-chitue-bo.html
            </a>
            <a>
                tibet-office-genf-bo.html
            </a>
            <a>
                chatrel.html(里边是pdf)
            </a>
            <a>
                download-bo.html
            </a>
            <a>
                partner-links-bo.html
            </a>
            <a>
                video-libary-bo.html
            </a>
            <a>
                photo-gallary-bo.html
            </a>
            <a>
                audios-tib.html
            </a>
            <a>
                news-archive-bo.html
            </a>
        </p>
        <P>
            时间：2018-01-08
        </P>
    </a>
    <a>
        <h3>
            atc_org_au
        </h3>
        <p>
            这个网站从主页进去抓不全，只能抓50个左右的新闻。起始链接是：https://www.atc.org.au/。添加了跟进板块和板块页数的链接之后，这个问题解决了。
        </p>
        <p>
            时间：2018-01-10
        </p>
    </a>
    <a>
        <h3>
            https://www.tibet-initiative.de/这个网站没法爬，因为这个网站板块分类不明确。
        </h3>
        <p>
            所以放弃了
        </p>
        <p>
            时间：2018-1-10
        </p>
    </a>
    <a>
        <h3>
            http://www.savetibet.org/
        </h3>
        <p>
            这个真的是全抓。里边的一个字段貌似有点问题，publish_user_id很多时候没有，而且新闻类的publish_user一般都是publish_user_href。所以我想
            新闻类的publish_user_href不是太重要吧！注意要将print的语句给注释掉。前边content内容字段的，没加join的要把join加上
        </p>
        <p>
            时间：2018-1-11
        </p>
    </a>
    <a>
        <h3>
            http://dhokhamchushigangdrug.com/
        </h3>
        <p>
            这个网站也有很多东西,可能是文档的网页一共只有两种类型。
            Your access to this site has been limited!!!!!!!!!!!
            这个烂网站还有反扒措施。。。。。。
        </p>
    </a>
    <a>
        <h3>
            http://www.chushigangdrug.ch/aktuelles/这个网站也是杂乱无章，还是用遍历的方法爬取
        </h3>
        <p>
            网站里边都是些什么东西额！！！网站里边的链接都无法跟进访问。明天调试内容：
            url的进一步跟进，更多网页版式的分类处理。不能通过start_requests来访问。
        </p>
        <p>
            时间：2018-01-12
        </p>
    </a>
    <a>
        <h3>
            http://www.tibetsociety.com/
        </h3>
        <P>
            遍历整个网站，这个相对容易一些
        </P>
        <p>
            时间：2018-01-12
        </p>
    </a>
    <a>
        <h3>
            xiongdeng多杰雄登，
        </h3>
        <p>
            想不到这个网站竟然还有论坛，！！！！！！！！！！！！！！！！,只爬取了p=123这样的网页
        </p>
        <p>
            时间：2018-01-12
        </p>
    </a>
    <a>
        <h3>
            tibetanentrepreneurs
        </h3>
        <p>
            这个网站跟进两中类型的链接，这个里边有不少外链，要做好allow_domain设置。跟进的是主页链接http://tibetanentrepreneurs.org/
        </p>-
        <p>
            时间：2018-01-12
        </p>
    </a>
    <a>
        <h3>
            ftchinese
        </h3>
        <p>
            这个网站得遍历抓取没有做好，reply_nodes也没有做好。
        </p>
    </a>
    <a>
        <h3>
            secretchina
        </h3>
        <p>
            并没有设置太多的关联规则，页面信息估计会抓不全。后边再做测试
        </p>
    </a>
    <a>
        <h3>
            chineseopen
        </h3>
        <p>
            这里边多数都是blog的文章,../blog/achivers/12345
        </p>
        <p>
            里边几乎没有评论，虽然有评论模块，但是评论不多。
        </p>
        <p>
            没有抓取到阅读次数，代码应该是正常的，至少在jupyter中是这样
        </p>
    </a>
    <a>
        <h3>radiosoh</h3>
        <p>
            这里的reply_count和nodes都没有写，因为感觉几乎没有评论。
        </p>
        <p>
            这个网站中文的板块有些少，只抓了china板块里边的内容。
        </p>
    </a>




</div>

</body>
</html>